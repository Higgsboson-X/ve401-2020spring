\section{Test for Statistics}

\subsection{Comparison of Two Means}

\begin{frame}{Basic Statistic}

\justifying
Suppose sample means $\overline{X}^{(1)}$ and $\overline{X}^{(2)}$ are calculated from samples of sizes $n_1$ and $n_2$ respectively from normal populations with means $\mu_1, \mu_2$ and variances $\sigma_1, \sigma_2$. Then since
\begin{align*}
\overline{X}^{(1)}\sim \U{N}(\mu_1, \sigma_1^2/n_1), \qquad \overline{X}^{(2)} \sim \U{N}(\mu_2, \sigma_2^2/n_2),
\end{align*}
the statistic
\begin{align*}
Z = \frac{\overline{X}^{(1)} - \overline{X}^{(2)} - (\mu_1 - \mu_2)}{\sqrt{\sigma_1^2/n_1 + \sigma_2^2/n_2}}
\end{align*}
follows a standard normal distribution.

\end{frame}


\begin{frame}{Variances Known}

\justifying
\structb{Variances known.} Let $X_1^{(i)}, \ldots, X_{n_i}^{(i)}$ with $i = 1, 2$ be samples of sizes $n_1$ and $n_2$ from normal distributions with unknown means $\mu_1, \mu_2$ and \highlightr{known} variances $\sigma_1^2, \sigma_2^2$. Then the test statistic is given by
\begin{align*}
Z = \frac{\overline{X}^{(1)} - \overline{X}^{(2)} - (\mu_1 - \mu_2)_0}{\sqrt{\sigma_1^2/n_1 + \sigma_2^2/n_2}}
\end{align*}
We reject at significance level $\alpha$
\begin{itemize}
	\item $H_0: \mu_1 - \mu_2 = (\mu_1-\mu_2)_0$ if $|Z| > z_{\alpha/2}$,
	\item $H_0: \mu_1 - \mu_2 \leq (\mu_1-\mu_2)_0$ if $Z > z_{\alpha}$,
	\item $H_0: \mu_1 - \mu_2 \geq (\mu_1-\mu_2)_0$ if $Z < -z_{\alpha}$.
\end{itemize}

\end{frame}


\begin{frame}{Variances Known}

\justifying
\structb{OC curve.} We can use the OC curves for normal distributions with
\begin{align*}
d = \frac{|(\mu_1-\mu_2)-(\mu_1-\mu_2)_0|}{\sqrt{\sigma_1^2+\sigma_2^2}}
\end{align*}
with $n = n_1 = n_2$. When $n_1\neq n_2$, we use the equivalent sample size
\begin{align*}
n = \frac{\sigma_1^2 + \sigma_2^2}{\sigma_1^2/n_1 + \sigma_2^2/n_2}.
\end{align*}

\end{frame}

\begin{frame}{Variances Equal but Unknown --- Student's $T$-Test}

\justifying
\structb{Variances equal but unknown.} Let $X_1^{(i)}, \ldots, X_{n_i}^{(i)}$ with $i = 1, 2$ be samples of sizes $n_1$ and $n_2$ from normal distributions with unknown means $\mu_1, \mu_2$ and \highlightr{equal} but \highlightr{unknown} variances $\sigma^2 = \sigma_1^2 = \sigma_2^2$. Then the test statistic is given by
\footnotesize
\begin{align*}
T_{n_1+n_2-2} = \frac{\overline{X}^{(1)} - \overline{X}^{(2)} - (\mu_1-\mu_2)_0}{\sqrt{S_p^2(1/n_1+1/n_2)}},
\end{align*}
\normalsize
with \highlightg{pooled estimator for variance}
\footnotesize
\begin{align*}
S_p^2 = \frac{(n_1-1)S_1^2 + (n_2-1)S_2^2}{n_1+n_2-2}.
\end{align*}
\normalsize
We reject at significance level $\alpha$
\begin{itemize}
	\item $H_0: \mu_1 - \mu_2 = (\mu_1-\mu_2)_0$ if $|T_{n_1+n_2-2}| > t_{\alpha/2, n_1+n_2-2}$,
	\item $H_0: \mu_1 - \mu_2 \leq (\mu_1-\mu_2)_0$ if $T_{n_1+n_2-2} > t_{\alpha,n_1+n_2-2}$,
	\item $H_0: \mu_1 - \mu_2 \geq (\mu_1-\mu_2)_0$ if $T_{n_1+n_2-2} < -t_{\alpha,n_1+n_2-2}$.
\end{itemize}

\end{frame}


\begin{frame}{Variances Equal but Unknown --- Student's $T$-Test}

\justifying
\structb{OC curve.} We use the OC curves for the T-test in case of equal sample sizes $n = n_1 = n_2$
\begin{align*}
d = \frac{|(\mu_1-\mu_2)-(\mu_1-\mu_2)_0|}{2\sigma}.
\end{align*}
When reading the charts, we must use the modified sample size $n^* = 2n-1$.

\end{frame}


\begin{frame}{Variances Unequal and Unknown --- Welch's $T$-test}

\justifying
\structb{Welch-Satterthwaite Relation.} Let $X^{(1)}, \ldots, X^{(k)}$ be $k$ independent normally distributed random variables with variances $\sigma_1^2, \ldots, \sigma_k^2$. Let $s_1^2, \ldots, s_k^2$ be sample variances based on samples of sizes $n_1, \ldots, n_k$ from the $k$ populations, respectively. Let $\lambda_1, \ldots, \lambda_k > 0$ be positive real numbers and define
\begin{align*}
\gamma := \frac{(\lambda_1 s_1^2 + \cdots + \lambda_k s_k^2)^2}{\displaystyle\sum_{i=1}^k \dfrac{(\lambda_i s_i^2)^2}{n_i-1} }.
\end{align*}
Then
\begin{align*}
\gamma \cdot \frac{\lambda_1 s_1^2 + \cdots + \lambda_k s_k^2}{\lambda_1 \sigma_1^2 + \cdots + \lambda_k \sigma_k^2}
\end{align*}
follows approximately a chi-squared distribution with $\gamma$ degrees of freedom, where we round $\gamma$ down to the nearest integer.


\end{frame}


\begin{frame}{Variances Unequal and Unknown --- Welch's $T$-test}

\justifying
\structb{Welch's T-test.} Let $X_1^{(i)}, \ldots, X_{n_i}^{(i)}$ with $i = 1, 2$ be samples of sizes $n_1$ and $n_2$ from normal distributions with unknown means $\mu_1, \mu_2$ and \highlightr{unequal} and \highlightr{unknown} variances $\sigma_1^2, \sigma_2^2$. The test statistic is given by
\begin{align*}
T_{\gamma} = \frac{\overline{X}^{(1)} - \overline{X}^{(2)} - (\mu_1-\mu_2)_0}{\sqrt{S_1^2/n_1 + S_2^2/n_2}}, \qquad \gamma = \frac{(S_1^2/n_1 + S_2^2/n_2)^2}{\dfrac{(S_1^2/n_1)^2}{n_1-1} + \dfrac{(S_2^2/n_2)^2}{n_2-1}}
\end{align*}
We reject at significance level $\alpha$
\begin{itemize}
	\item $H_0: \mu_1-\mu_2 = (\mu_1-\mu_2)_0$ if $T_{\gamma} > t_{\alpha/2,\gamma}$,
	\item $H_0: \mu_1-\mu_2 \leq (\mu_1-\mu_2)_0$ if $T_{\gamma} > t_{\alpha,\gamma}$,
	\item $H_0: \mu_1-\mu_2 \geq (\mu_1-\mu_2)_0$ if $T_{\gamma} < -t_{\alpha,\gamma}$.
\end{itemize}



\end{frame}


\subsection{Non-parametric Comparisons}


\begin{frame}{Wilcoxon Rank-Sum Test}

\justifying
\structb{Wilcoxon rank-sum test.} Let $X$ and $Y$ be two random populations following some continuous distributions. \\
~\\
Let $X_1, \ldots, X_m$ and $Y_1, \ldots, Y_n$, where $m\leq n$, be random samples from $X$ and $Y$ and associate the rank $R_i, i = 1,\ldots, m+n$, to the $R_i$th smallest among the $m+n$ total observations. If ties in the rank occur, the mean of the ranks is assigned to all equal values. The test statistic is given by
\begin{align*}
W_m = \U{sum\ of\ the\ ranks\ of\ } X_1, \ldots, X_m
\end{align*}
We reject $H_0: P[X > Y]$ at significance level $\alpha$ if $W_m$ falls into the corresponding critical region. 


\end{frame}


\begin{frame}{Wilcoxon Rank-Sum Test}

\justifying
\structb{Wilcoxon rank-sum test.} For large values of $m (m\geq 20)$, $W_m$ is approximated normally distributed with
\begin{align*}
\U{E}[W_m] = \frac{m(m+n+1)}{2}, \qquad \U{Var}[W_m] = \frac{mn(m+n+1)}{12}.
\end{align*}
In case of ties, the variance may be corrected by taking
\begin{align*}
\U{Var}[W_m] = \frac{mn(m+n+1)}{12-\displaystyle \sum_{\U{groups}} \frac{t^3+t}{12}},
\end{align*}
where the sum is taken over all groups of $t$ ties.


\end{frame}



\subsection{Paired Tests}


\begin{frame}{Paired $T$-Test}

\justifying
\structb{Paired T-test.} Let $X_1^{(i)}, \ldots, X_{n_i}^{(i)}$ with $i = 1, 2$ be samples of size $n = n_1 = n_2$ from normal distributions with unknown means $\mu_1, \mu_2$ and \highlightr{equal} but \highlightr{unknown} variances $\sigma^2 = \sigma_1^2 = \sigma_2^2$. Then $D_i = X_i - Y_i$ follows normal distributions. Then the test statistic is given by
\begin{align*}
T_{n-1} = \frac{\overline{D} - \mu_0}{\sqrt{S^2_D/n}}.
\end{align*}
We reject at significance level $\alpha$
\begin{itemize}
	\item $H_0: \mu_D = \mu_0$ if $|T_{n-1}| > t_{\alpha/2,n-1}$,
	\item $H_0: \mu_D \leq \mu_0$ if $T_{n-1} > t_{\alpha,n-1}$,
	\item $H_0: \mu_D \geq \mu_0$ if $T_{n-1} < -t_{\alpha,n-1}$.
\end{itemize}


\end{frame}

\begin{frame}{Paired vs. Pooled $T$-Tests}

\justifying
With two populations $X$ and $Y$ with equal variances $\sigma^2$, we want to test $H_0: \mu_X = \mu_Y$ using samples of equal size $n$. Then the statistics are
\footnotesize
\begin{align*}
T_{\U{pooled}} & = \frac{\overline{X} - \overline{Y}}{\sqrt{2S_p^2/n}}, \qquad \U{critical\ value} = t_{\alpha/2,2n-2}, \\
T_{\U{paired}} & = \frac{\overline{X}-\overline{Y}}{\sqrt{S_D^2/n}}, \qquad \U{critical\ value} = t_{\alpha/2,n-1}.
\end{align*}
\normalsize
Preferring a more powerful test, we consider the following.
\begin{itemize}
	\justifying
	\item $t_{\alpha/2,2n-2} < t_{\alpha/2,n-1}$, smaller critical values $\Rightarrow$ easier to reject.
	\item $2S_p^2/n$ estimates $2\sigma^2/n$, while $S_D^2/n$ estimates $\sigma_D^2/n = \sigma_{\overline{D}}^2$, where
	\footnotesize
	\begin{align*}
	\sigma_{\overline{D}}^2 = \frac{2\sigma^2}{n}(1-\rho_{\overline{X}\overline{Y}}) = \frac{2\sigma^2}{n}(1-\rho_{XY}).
	\end{align*}
	\normalsize
	When $\rho_{XY} > 0$, paired T-test would be more powerful.
\end{itemize}

\end{frame}


\begin{frame}{Non-parametric Paired Test}

\justifying
\structb{Comparison of medians.} Let $X$ and $Y$ be two independent random variables that follow the same distribution but differ only in their location, i.e., $X':=X-\delta$ and $Y$ are independent and identically distributed. Then $D = X - Y$ and $2\delta-D$ follow the same distribution. Therefore, $D$ is symmetric about $\delta$.
\begin{align*}
f_D(d-\delta) = f_D(\delta-d).
\end{align*}
Then we can perform the Wilcoxon signed-rank test on $D$.

\end{frame}


\subsection{Correlation Coefficient}

\begin{frame}{Estimating Correlation}

\structb{Estimator for correlation.} The unbiased estimators for variance and covariance are given by
\begin{align*}
\widehat{\U{Var}[X]} & = \frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2, \\
\widehat{\U{Var}[Y]} & = \frac{1}{n-1}\sum_{i=1}^n(Y_i-\overline{Y})^2, \\
\widehat{\U{Cov}[X, Y]} & = \frac{1}{n-1} \sum_{i=1}^n (X_i-\overline{X})(Y_i-\overline{Y}),
\end{align*}
giving
\begin{align*}
R := \widehat{\rho} = \frac{\sum(X_i-\overline{X})(Y_i-\overline{Y})}{\sqrt{\sum(X_i-\overline{X})^2}\sqrt{\sum(Y_i-\overline{Y})^2}}.
\end{align*}

\end{frame}

\begin{frame}{Hypothesis Tests for the Correlation Coefficient}

\justifying
\structb{Distribution.} Suppose $(X, Y)$ follows a bivariate normal distribution with relation coefficient $\rho\in (-1, 1)$. For large sample size $n$, the Fisher transformation of $R$
\begin{align*}
\frac{1}{2}\ln\left(\frac{1+R}{1-R} \right) = \U{Artanh}(R) 
\end{align*}
is approximately normal with
\begin{align*}
\mu = \frac{1}{2}\ln\left(\frac{1+\rho}{1-\rho} \right) = \U{Artanh}(\rho), \qquad \sigma^2 = \frac{1}{n-3}.
\end{align*}

\end{frame}

\begin{frame}{Hypothesis Tests for the Correlation Coefficient}

\justifying
\structb{Confidence interval.} A $100(1-\alpha)\%$ confidence interval for $\rho$ is given by
\begin{align*}
\left[\frac{1+R-(1-R)e^{2z_{\alpha/2}/\sqrt{n-3}}}{1+R+(1-R)e^{2z_{\alpha/2}/\sqrt{n-3}}},  \frac{1+R-(1-R)e^{-2z_{\alpha/2}/\sqrt{n-3}}}{1+R+(1-R)e^{-2z_{\alpha/2}/\sqrt{n-3}}}\right]
\end{align*}
or
\begin{align*}
\tanh\left(\U{Artanh}(R) \pm \frac{z_{\alpha/2}}{\sqrt{n-3}} \right).
\end{align*}


\end{frame}


\begin{frame}{Hypothesis Tests for the Correlation Coefficient}

\justifying
Suppose $X_1, \ldots, X_n$ and $Y_1, \ldots, Y_n$ are samples of size $n$ from $X$ and $Y$, where $(X, Y)$ follows a bivariate normal distribution with relation coefficient $\rho\in (-1, 1)$. The test statistic is given by
\begin{align*}
Z & = \frac{\sqrt{n-3}}{2}\left(\ln\left(\frac{1+R}{1-R} \right) - \ln\left(\frac{1+\rho_0}{1-\rho_0} \right) \right) \\
& = \sqrt{n-3}(\U{Artanh}(R) - \U{Artanh}(\rho_0)).
\end{align*}
We reject at significance level $\alpha$
\begin{itemize}
	\item $H_0: \rho = \rho_0$ if $|Z| > z_{\alpha/2}$,
	\item $H_0: \rho \leq \rho_0$ if $Z > z_{\alpha}$,
	\item $H_0: \rho \geq \rho_0$ if $Z < -z_{\alpha}$.
\end{itemize}


\end{frame}


\section{Categorical Data}





