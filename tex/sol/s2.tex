\section*{Closeness of Binomial and Poisson Distributions}

For $n\in \N\setminus\{0\}, 0 < p < 1$, suppose $f(x; n, p)$ denotes the probability density function of binomial distribution with parameters $n$ and $p$, while $f(x; k)$ denotes the probability density function of Poisson distribution with parameter $k$. Let $\{p_n\}_{n=1}^{\infty}$ be a sequence of numbers between 0 and 1 such that
\begin{align*}
\lim_{n\rightarrow\infty} np_n = k,
\end{align*}
then
\begin{align*}
\lim_{n\rightarrow \infty} f(x; n, p_n) = f(x; k), \qquad \U{for\ all\ } x = 0, 1, \ldots
\end{align*}
~\\
\textbf{Proof.} The probability density function for binomial distribution is given by
\begin{align*}
f(x; n, p_n) = \frac{n(n-1)\cdots (n-x+1)}{x!}p_n^x (1-p_n)^{n-x}.
\end{align*}
Suppose $k_n = np_n$ so that $\lim_{n\rightarrow \infty} k_n = k$. Then the expression above can be rewritten as 
\begin{align*}
f(x; n, p_n) = \frac{k_n^x}{x!}\cdot \frac{n}{n}\cdot \frac{n-1}{n}\cdots \frac{n-x+1}{n}\left(1 - \frac{k_n}{n} \right)^n \left(1 - \frac{k_n}{n} \right)^{-x}.
\end{align*}
Furthermore, for each $x\geq 0$,
\begin{align*}
\lim_{n\rightarrow \infty} \frac{n}{n} \cdot \frac{n-1}{n}\cdots \frac{n-x+1}{n}\left(1 - \frac{k_n}{n} \right)^{-x} = 1,
\end{align*}
and
\begin{align*}
\lim_{n\rightarrow \infty} \left(1 - \frac{k_n}{n} \right)^n = e^{-k}.
\end{align*}
Therefore,
\begin{align*}
\lim_{n\rightarrow \infty} f(x; n, p_n) = \frac{k^xe^{-k}}{x!} = f(x; k).
\end{align*}

\section*{Part 1 Exercise 1.}

Suppose Keven plays a game where he has probability $p$ to win in each play. When he wins, his fortune is doubled, and when he loses, his fortune is cut in half. If he begins playing with a given fortune $c > 0$, what is the expected value of his fortune after $n$ independent plays? \\
~\\
\textbf{Solution.} Define a random variable $X_i, i = 1, \ldots, n$, where $X_i = 2$ if Keven's fortune is doubled on the $i$-th play and $X_i = 1/2$ if his fortune is cut in half on the $i$-th play. Then
\begin{align*}
\U{E}[X_i] = 2p + \frac{1}{2}(1-p) = \frac{1}{2}(1 + 3p).
\end{align*}
Because the plays are independent from each other, the expected final fortune is
\begin{align*}
c\U{E}[X_1\cdots X_n] = c\times \U{E}[X_1]\cdots \U{E}[X_n] = \frac{c}{2^n}(1+3p)^n.
\end{align*}


\section*{Part 1 Exercise 2.}

For $0 < p < 1$ and $n = 2, 3, \ldots$, determine the value of
\begin{align*}
\sum_{x=2}^n x(x-1)\binom{n}{x} p^x(1-p)^{n-x}.
\end{align*}
~\\
\textbf{Solution.} Changing the lower limit of the summation from $x = 2$ to $x = 0$, we obtain
\begin{align*}
\sum_{x=0}^n x^2\binom{n}{x} p^x(1-p)^{n-x} - \sum_{x=0}^n x\binom{n}{x} p^x(1-p)^{n-x}.
\end{align*}
If $X$ has the binomial distribution with parameters $n$ and $p$, then the two terms in the summation are $\U{E}[X^2]$ and $\U{E}[X]$, respectively. Therefore,
\begin{align*}
\U{E}[X^2] - \U{E}[X] & = \U{Var}[X] + \U{E}[X]^2 - \U{E}[X] \\
& = np(1-p) + (np)^2 - np \\
& = n(n-1)p^2.
\end{align*}
\underline{\textbf{Note}}. Not limited to this example, it is useful in general to calculate some integrals (especially in statistics) if we know the probability density functions, expectations and variances of some common distributions.

\section*{Part 1 Exercise 3.}

Suppose that a book with $n$ pages contains on the average $\lambda$ misprints per page. What is the probability that there will be at least $m$ pages which contain more than $k$ misprints? \\
~\\
\textbf{Solution.} Let $Y$ denote the number of misprints on a given page. Then the probability $p$ that a given page will contain more than $k$ misprints is
\begin{align*}
p = P[Y > k] = \sum_{i=k+1}^{\infty} f(i; \lambda) = \sum_{i=k+1}^{\infty} \frac{\lambda^i e^{-\lambda}}{i!},
\end{align*}
and
\begin{align*}
1 - p = \sum_{i=0}^k f(i; \lambda) = \sum_{i=0}^{k} \frac{\lambda^i e^{-\lambda}}{i!}.
\end{align*}
Let $X$ denote the number of pages among $n$ pages in the book, where there are more than $k$ misprints. Then for $x = 0, 1, \ldots, n$,
\begin{align*}
P[X = x] = \binom{n}{x} p^x(1-p)^{n-x},
\end{align*}
which gives
\begin{align*}
P[X\geq m] = \sum_{x=m}^n \binom{n}{x} p^x(1-p)^{n-x},
\end{align*}
where $p$ is given by the formula above.


\section*{Part 2 Exercise 1.}

Suppose that a certain system contains three components $C_1, C_2, C_3$ that function independently of each other and are connected as series, so that the system fails as soon as one of the components fails. Suppose that the length of life of the $C_1, C_2, C_3$ has the exponential distribution with parameters
\begin{align*}
\beta_1 = 0.001, \qquad \beta_2 = 0.003, \qquad \beta_3 = 0.006,
\end{align*}
respectively, all measured in hours. Determine the probability that the system will not fail before 100 hours.\\
~\\
\textbf{Solution.} Let $Y$ denote the length of life of the system, and $X_1, X_2, X_3$ are the lifetime of each component. Then for any $y > 0$,
\begin{align*}
P[Y > y] & = P[X_1 > y, X_2 > y, X_3 > y] \\
& = P[X_1 > y]P[X_2 > y]P[X_3 > y] \\
& = e^{-(\beta_1 + \beta_2 + \beta_3)y}.
\end{align*}
Therefore,
\begin{align*}
P[Y > 100] = e^{-100\times 0.01} = \frac{1}{e}.
\end{align*}


\section*{Part 2 Exercise 2.}

Let $X_1, X_2, X_3$ be independent lifetimes of memory chips. Suppose each $X_i$ follows the normal distribution with mean 300 hours and standard deviation 10 hours. Compute the probability that at least one of the three chips lasts at least 290 hours. \\
~\\
\textbf{Solution.} Let $A_i$ be the event that chip $i$ lasts at most 290 hours. Then the probability of interest is given by
\begin{align*}
P & = \bigcup_{i=1}^3 A_i^c \\
& = 1 - P\left[\bigcap_{i=1}^3 A_i \right] \\
& = 1 - \prod_{i=1}^3 P[A_i].
\end{align*}
Since the lifetime of each chip has the normal distribution with mean 300 and standard deviation 10, each $A_i$ has probability
\begin{align*}
F\left(\frac{290 - 300}{10} \right) = F(-1) = 1 - 0.8413 = 0.1587.
\end{align*}
Therefore,
\begin{align*}
P = 1 - 0.1587^3 = 0.996.
\end{align*}
